<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Python 日志模块 logging 的应用]]></title>
    <url>%2FPython-%E6%97%A5%E5%BF%97%E6%A8%A1%E5%9D%97-logging-%E7%9A%84%E5%BA%94%E7%94%A8.html</url>
    <content type="text"><![CDATA[日志是程序员工具箱中非常有用的工具.它可以帮助你更好地理解程序的流程,并在开发过程中发现你可能没有想到的场景. 日志为开发人员提供了一双额外的眼睛,这些眼睛不断关注应用程序正在执行的流程.它们可以存储信息,例如访问应用程序的用户或IP.如果发生错误,那么日志可以告诉你程序在到达发生错误的代码行之前的状态,它们可以提供比内存堆栈跟踪更多的信息. 通过从正确的位置记录有用的数据,你不仅可以轻松地调试错误,还可以使用数据分析应用程序的性能以及规划营销方案. Python 提供了一个日志系统作为其标准库的一部分,因此你可以快速向你的应用程序添日志.在本文中,你将了解为什么使用此模块是向应用程序添加日志以及如何快速入门的最佳方式,并且了解一些高级功能. Logging 模块Python 中的 logging 模块是一个随时可用且功能强大的模块,旨在满足初学者和企业团队的需求.它被大多数第三方Python库使用,因此你可以将日志消息与这些库中的日志消息集成,以便为你的应用程序生成同类日志. 将记录添加到Python程序就像这样简单: 1import logging 导入 logging 模块后,你可以使用被称为 “logger” 来记录你要查看的消息.默认情况下有5个标准级别说明事件的严重性.每个都有一个相应的方法,可用于记录该严重级别的事件.按严重程度增加的顺序定义的级别如下: DEBUG INFO WARNING ERROR CRITICAL logging 模块为你提供了一个默认 logger,允许你在不进行太多配置的情况下开始使用.可以调用每个级别的相应方法,如以下示例所示: 1234567import logginglogging.debug(&apos;This is a debug message&apos;)logging.info(&apos;This is an info message&apos;)logging.warning(&apos;This is a warning message&apos;)logging.error(&apos;This is an error message&apos;)logging.critical(&apos;This is a critical message&apos;) 上述程序的输出如下所示: 123WARNING: root: This is a warning messageERROR: root: This is an error messageCRITICAL: root: This is a critical message 每条输出消息显示的严重性级别后面的 root,即 logging 模块为其默认 logger 提供的名称.（ Loggers 将在后面的章节中详细讨论.）此格式显示由冒号（: ）分隔的级别,名称和消息,这是默认输出格式,可配置的内容包括时间戳,行号等内容细节. 请注意,这里没有记录 debug() 和 info() 消息.这是因为默认情况下 logging 模块会记录严重性级别为 WARNING 或超过 WARNING 的信息.你可以通过根据需要将 logging 模块配置为记录所有级别的事件.你还可以通过更改配置来定义自己的严重性级别,但通常不建议这样做,因为它可能会导致你可能正在使用的某些第三方库的日志混淆. 基本配置你可以使用该方法配置 logging: basicConfig(**kwargs) “你会注意到 logging 模块会破坏PEP8规范并使用 camelCase 命名约定.这是因为它是参考 Java 的 logging 库 Log4j.这是这个包中的一个已知问题,但在决定将它添加到标准库时,它已经被用户接受并且修改这个问题以满足PEP8规范导致向后兼容性问题.“ (Source) 一些常用的参数 basicConfig() 如下: level: 为 root logger 设置指定的严重性级别.filename: 指定日志输出文件.filemode: 如果 filename 存在,则以此模式打开文件.默认值为a,表示追加.format: 这里设置日志消息的格式.通过使用修改 level 参数,你可以设置要记录的日志消息级别.这可以通过传递类中的一个可用常量来完成,这将允许记录该级别或更高级别的所有 logging 调用.举个例子: 1234import logginglogging.basicConfig(level=logging.DEBUG)logging.debug(&apos;This will get logged&apos;) 1DEBUG: root: This will get logged 现在将记录所有级别或者比DEBUG更高级别的事件. 同样,对于记录信息到文件而不是控制台,需要启用 filename 和 filemode,你可以使用 format 确定消息的格式.以下示例显示了几个用法:1234import logginglogging.basicConfig(filename=&apos;app.log&apos;, filemode=&apos;w&apos;, format=&apos;%(name)s - %(levelname)s - %(message)s&apos;)logging.warning(&apos;This will get logged to a file&apos;) 1root - ERROR - This will get logged to a file 消息将如下所示,但日志将写入名为 app.log 的文件而不是控制台.filemode 设置为 w,这意味着每次 basicConfig() 调用日志文件都以“写入模式”打开,程序的每次运行都将重写该文件. filemode 的默认配置 a 是 append 追加. 你可以使用更多参数在 basicConfig() 进一步自定义root logger. 需要注意的是 basicConfig() 只有在之前没有配置 root logger 的情况下,才能调用方法配置 root logger.基本上这个函数只能调用一次. debug(),info(),warning(),error(),和 critical() 也调用 basicConfig() 如果它之前没有调用, 默认没有参数.这意味着在第一次调用上述函数之一后,你无法再配置 root logger,因为它们会在 basicConfig() 内部调用该函数. basicConfig() 是默认将 logger 设置为以下列格式写入控制台:1ERROR: root: This is an error message 格式化输出虽然你可以将任何可以表示为字符串的变量作为消息传递给你的日志,但是有些基本元素已经是其中的一部分,LogRecord 可以轻松添加到输出格式中.如果要将进程ID与级别和消息一起记录,可以执行以下操作:1234import logginglogging.basicConfig(format=&apos;%(process)d-%(levelname)s-%(message)s&apos;)logging.warning(&apos;This is a Warning&apos;) 118472-WARNING-This is a Warning format 可以 LogRecord 在你喜欢的任何排列中使用带有属性的字符串.可以在此处找到可用属性的完整列表. 这是另一个可以添加日期和时间信息的示例:1234import logginglogging.basicConfig(format=&apos;%(asctime)s - %(message)s&apos;, level=logging.INFO)logging.info(&apos;Admin logged in&apos;) 12018-07-11 20: 12: 06,288 - Admin logged in %(asctime)s 增加了 LogRecord 的创建时间.可以使用 datefmt 属性更改格式,该属性使用与 datetime 模块中的格式化函数相同的格式化语言,例如 time.strftime():1234import logginglogging.basicConfig(format=&apos;%(asctime)s - %(message)s&apos;, datefmt=&apos;%d-%b-%y %H: %M: %S&apos;)logging.warning(&apos;Admin logged out&apos;) 112-Jul-18 20: 53: 19 - Admin logged out 你可以在这里找到指南. 记录变量数据在大多数情况下,你可能希望在日志中包含应用程序中的动态信息.你已经看到 logging 方法将字符串作为参数,并且在单独的行中使用可变数据格式化字符串并将其传递给 log 方法似乎很自然.但实际上,这可以通过使用消息的格式字符串并将变量数据作为参数附加来直接完成.这是一个例子:12345import loggingname = &apos;John&apos;logging.error(&apos;%s raised an error&apos;, name) 1ERROR: root: John raised an error 传递给该方法的参数将作为可变数据包含在消息中. 虽然你可以使用任何格式化样式,但 Python 3.6 中引入的f字符串是格式化字符串. 这是一种很棒的方法,因为它们可以帮助保持格式简短易读:12345import loggingname = &apos;John&apos;logging.error(f&apos;&#123;name&#125; raised an error&apos;) 1ERROR: root: John raised an error 跟踪内存堆栈logging 模块还允许你捕获应用程序中的完整堆栈跟踪.如果 exc_info 参数传递为 True,则可以捕获异常信息,并且像这样调用 logging 函数:123456789import logginga = 5b = 0try: c = a / bexcept Exception as e: logging.error(&quot;Exception occurred&quot;, exc_info=True) 123456ERROR: root: Exception occurredTraceback (most recent call last): File &quot;exceptions.py&quot;, line 6, in &lt;module&gt; c = a / bZeroDivisionError: division by zero[Finished in 0.2s] 如果 exc_info 未设置为 True,则上述程序的输出不会告诉我们任何有关异常的信息,在实际情况中,该异常可能不像a那样简单ZeroDivisionError.想象一下,尝试使用仅显示以下内容的日志调试复杂代码库中的错误:1ERROR: root: Exception occurred 这是一个快速提示: 如果你从异常 Handlers 进行 logging ,请使用该 logging.exception() 方法,该方法使用级别记录消息ERROR并将异常信息添加到消息中.更简单地说,调用logging.exception() 就像调用一样 logging.error(exc_info=True).但由于此方法始终转储异常信息,因此只应从异常 Handlers 调用它.看看这个例子:12345678import logginga = 5b = 0try: c = a / bexcept Exception as e: logging.exception(&quot;Exception occurred&quot;) 123456ERROR: root: Exception occurredTraceback (most recent call last): File &quot;exceptions.py&quot;, line 6, in &lt;module&gt; c = a / bZeroDivisionError: division by zero[Finished in 0.2s] 使用 logging.exception() 将显示 ERROR 级别的日志.如果你不希望出现这种情况,你可以从调用任何其他的方法如 debug() 或者 critical() 并传递 exc_info 参数作为 True. 类和函数在使用 logging 模块的过程中, 我们可以发现只要直接这样调用 logging.debug(), 就可以看到名字是 root 的默认 logger.你可以（并且应该）通过创建 Logger 类的对象来定义自己的 logger,尤其是在应用程序具有多个模块的情况下.我们来看看模块中的一些类和函数. logging 模块中定义的最常用类如下: Logger: 这是一个类,其对象将直接在应用程序代码中用于调用函数. LogRecord: Logger 自动创建的 LogRecord 对象具有与记录事件相关的所有信息,例如 Logger 的名称,功能,行号,消息等. Handler: Handler 发送 LogRecord 到需要的输出终点, 例如控制台或者文件.Handler 有一些子类, 例如 StreamHandler, FileHandler, SMTPHandler, HTTPHandler,等等.这些子类将 logging 发送到相应的目标,如 sys.stdout 或者磁盘文件. Formatter: 这是指定输出应包含的属性的字符串格式来指定输出格式. 其中,我们主要处理 Logger 类的对象,这些对象使用模块级函数进行实例化 logging.getLogger(name).getLogger() 使用相同的重复调用相同的 name 将返回对同一 Logger 对象的引用,这使我们无法将 logger 对象传递到需要它的每个部分.这是一个例子:1234import logginglogger = logging.getLogger(&apos;example_logger&apos;)logger.warning(&apos;This is a warning&apos;) 1This is a warning 这将创建一个名为 example_logger 的自定义 logger ,但与 root logger 不同,自定义 logger 的名称不是默认输出格式的一部分,必须添加到配置中.将其配置为显示 logger 名称的格式将得到如下输出:1WARNING: example_logger: This is a warning 同样,与 root logger 不同,无法使用自定义 logger 进行配置 basicConfig().你必须使用 Handlers 和 formatter 对其进行配置: “我们建议使用模块级 loggers 时传递 name 作为 name 参数给 getLogger() 来创建一个 logger 对象,因为 logger 本身的名称会告诉我们记录事件的位置.name 是Python中一个特殊的内置变量,它会返回当前模块的名称.“ （来源） 使用 Handlers当你想要配置自己的 logger 并在生成日志时将日志发送到多个位置时,就会用到 Handlers. Handlers 将日志消息发送到已配置的目标（如标准输出流或文件或HTTP）或通过SMTP发送到你的电子邮件. 你创建的 logger 可以有多个 Handlers ,这意味着你可以将其设置为保存到日志文件并通过电子邮件发送. 与 logger 一样,你也可以在 Handlers 中设置严重性级别.如果要为同一 logger 设置多个 Handlers 但希望每个 Handlers 具有不同的严重性级别,这将非常有用.例如,你可能希望将具有级别 WARNING 及更高级别的 logging 到控制台,但是具有级别 ERROR 及更高级别的所有内容也应保存到文件中.这是一个执行此操作的程序: #logging_example.py12345678910111213141516171819202122232425# logging_example.pyimport logging# Create a custom loggerlogger = logging.getLogger(__name__)# Create handlersc_handler = logging.StreamHandler()f_handler = logging.FileHandler(&apos;file.log&apos;)c_handler.setLevel(logging.WARNING)f_handler.setLevel(logging.ERROR)# Create formatters and add it to handlersc_format = logging.Formatter(&apos;%(name)s - %(levelname)s - %(message)s&apos;)f_format = logging.Formatter(&apos;%(asctime)s - %(name)s - %(levelname)s - %(message)s&apos;)c_handler.setFormatter(c_format)f_handler.setFormatter(f_format)# Add handlers to the loggerlogger.addHandler(c_handler)logger.addHandler(f_handler)logger.warning(&apos;This is a warning&apos;)logger.error(&apos;This is an error&apos;) 12__main__ - WARNING - This is a warning__main__ - ERROR - This is an error 在这里,logger.warning() 创建一个 LogRecord 包含事件的所有信息并将其传递给它拥有的所有 Handlers : c_handler和f_handler. c_handler 是一个 StreamHandler 有 WARNING 级别的 LogRecord 并从中获取信息以生成指定格式的输出并将其打印到控制台.f_handler 是一个 FileHandler 有 ERROR 级别的 LogRecord,忽略 LogRecord 中 WARNING 级别的信息. 当调用 logger.error() 时,c_handler 行为与以前完全相同,而且 f_handler 获得一个 ERROR 级别 LogRecord,因此它继续生成输出c_handler,但不是将其打印到控制台,而是以这种格式将其写入指定的文件:12018-08-03 16: 12: 21,723 - __main__ - ERROR - This is an error 将与 name 变量对应的 logger 的名称记录为 main,这是 Python 分配给执行开始的模块的名称.如果此文件由某个其他模块导入,则该 name 变量将对应于其名称logging_example.这是它的样子:123# run.pyimport logging_example 12logging_example - WARNING - This is a warninglogging_example - ERROR - This is an error 其他配置方法你可以使用模块和类函数配置 logging ,或者通过创建配置文件或字典并使用 fileConfig() 或 dictConfig() 分别加载文件或字典来配置 logging.如果要在正在运行的应用程序中更改 logging 配置,这些选项非常有用. 这是一个示例文件配置:123456789101112131415161718192021222324252627282930[loggers]keys=root,sampleLogger[handlers]keys=consoleHandler[formatters]keys=sampleFormatter[logger_root]level=DEBUGhandlers=consoleHandler[logger_sampleLogger]level=DEBUGhandlers=consoleHandlerqualname=sampleLoggerpropagate=0[handler_consoleHandler]class=StreamHandlerlevel=DEBUGformatter=sampleFormatterargs=(sys.stdout,)[formatter_sampleFormatter]format=%(asctime)s - %(name)s - %(levelname)s - %(message)s[formatter_sampleFormatter] format = ％（asctime）s - ％（name）s - ％（levelname）s - ％（message）s 在上面的文件中,有两个 logger ,一个 Handlers 和一个 formatter .定义它们的名称后,可以通过在名称用下划线分隔之前添加 logger,handler 和 formatter 来配置它们. 要加载此配置文件,你必须使用fileConfig():123456789import loggingimport logging.configlogging.config.fileConfig(fname=&apos;file.conf&apos;, disable_existing_loggers=False)# Get the logger specified in the filelogger = logging.getLogger(__name__)logger.debug(&apos;This is a debug message&apos;) 12018-07-13 13: 57: 45,467 - __main__ - DEBUG - This is a debug message 配置文件的路径作为参数传递给 fileConfig() 方法, disable_existing_loggers 参数用于保持或禁用调用函数时存在的 logger .如果没有设置则默认为 True. 以下是字典方法的YAML格式的相同配置:123456789101112131415161718version: 1formatters: simple: format: &apos;%(asctime)s - %(name)s - %(levelname)s - %(message)s&apos;handlers: console: class: logging.StreamHandler level: DEBUG formatter: simple stream: ext: //sys.stdoutloggers: sampleLogger: level: DEBUG handlers: [console] propagate: noroot: level: DEBUG handlers: [console] 这是一个示例,显示如何从yaml文件加载配置:1234567891011import loggingimport logging.configimport yamlwith open(&apos;config.yaml&apos;, &apos;r&apos;) as f: config = yaml.safe_load(f.read()) logging.config.dictConfig(config)logger = logging.getLogger(__name__)logger.debug(&apos;This is a debug message&apos;) 12018-07-13 14: 05: 03,766 - __main__ - DEBUG - This is a debug message 保持冷静, 然后查看日志logging 模块被认为非常灵活.它的设计非常实用,应该适合你的开箱即用.你可以将基本 logging 添加到一个小项目中,或者如果你正在处理一个大项目,则可以创建自己的自定义log levels, Handlers 类等. 如果你还没有在应用程序中使用 logging ,那么现在是开始的好时机.如果做得好, logging 肯定会消除开发过程中的大量摩擦,并帮助你找到将应用程序提升到新水平的机会. 转自: https://realpython.com/python-logging/]]></content>
      <categories>
        <category>Python</category>
        <category>Tutorial</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Tutorial</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我一直不理解 JavaScript 的闭包是什么]]></title>
    <url>%2F%E6%88%91%E4%B8%80%E7%9B%B4%E4%B8%8D%E7%90%86%E8%A7%A3%20JavaScript%20%E7%9A%84%E9%97%AD%E5%8C%85.html</url>
    <content type="text"><![CDATA[我一直不理解 JavaScript 的闭包是什么直到有人这样向我解释…… 原文:https://medium.com/dailyjs/i-never-understood-javascript-closures-9663703368e8 施工未完成, 有空再填坑 正如标题所述，JavaScript 的闭包对我来说一直是个谜一样的存在。我看过很多篇讲闭包的文章，也在工作中用过闭包，有时甚至在我没有意识到到的情况下使用了闭包.即使这样我还是不太明白 JavaScript 的闭包是什么. 最近我去了一个演讲，终于有人让我明白了什么是闭包。我会尝试用这种方法来解释本文中的闭包。让我们赞扬 CodeSmith 的优秀人才和他们的 JavaScript The Hard Parts 系列。 在开始之前在你开始理解闭包之前，有些很重要的概念需要讲一下。其中之一是 执行上下文(execution context)。 这是一篇很好对执行上下文入门的文章。引用这篇文章： 在运行 JavaScript 代码时，它的执行上下文非常重要，并被判断为以下的其中一个：全局代码 - 首次执行代码的默认环境。功能代码 - 每当执行流程进入函数体时。（……）（…），让我们将该术语 execution context视为正在解析当前代码的环境/范围。 换句话说，当我们启动程序时，我们从 全局执行上下文(global execution context) 开始。一些变量在全局执行上下文中声明。我们称这些变量为全局变量。当程序调用函数时，会发生什么？几个步骤： JavaScript 创建一个新的执行上下文，一个 局部执行上下文(local execution context) 这个局部执行上下文将具有其自己的变量集，这些变量将是该执行上下文的局部变量。 新的执行上下文被抛到 执行堆栈(execution stack) 上。可以将执行堆栈视为一种机制，用于跟踪程序执行的位置 什么时候函数会结束执行？当遇到 return 声明或遇到结束括号 } 时。函数结束时，会发生以下情况： 局部执行上下文 从执行堆栈中弹出 函数将返回值发送回 调用上下文(calling context)。调用上下文是调用此函数的执行上下文，它可以是全局执行上下文或另一个局部执行上下文。由调用上下文来处理这个函数的返回值。返回的值可以是对象，数组，函数，布尔值，任何东西。如果函数没有return语句，则返回undefined。 局部执行上下文会被销毁。这里很重要。在局部执行上下文中声明的所有变量都将被删除。他们不再可用。这就是他们被称为局部变量的原因。 举一个非常基本的例子在我们开始理解闭包之前，让我们看一下下面这段代码。这个例子看起来非常简单，任何读这篇文章的人都可能知道它的作用。12345671：let a = 3 2：function addTwo（x）&#123; 3： let ret = x + 2 4： return ret 5：&#125; 6：let b = addTwo（a）7：console.log（b） 为了理解 JavaScript 真正工作原理，让我们详细介绍一下。 在第1行我们在全局执行上下文中声明一个新变量 a，并为其分配数字 3。 接下来它变得有点复杂。第 2 到第 5 行被包含在一起。这里发生了什么？我们在全局执行上下文中声明了一个以 addTwo 命名的新变量。我们分配给它的是什么？函数定义。两个括号之间{ }的任何内容都分配给 addTwo。函数内部的代码不会被解析，也不会执行，只是存储到变量中以备将来使用。 所以现在我们来看看第6行。它看起来很简单，但在这里解析了很多。首先，我们在全局执行上下文中声明一个新变量并命名它为 b。声明变量后，它的值为undefined。 接下来仍然是第6行，我们看到一个赋值运算符 =。我们正准备为变量 b 分配一个新值。我们可以看到一个函数被调用。当你看到变量后跟圆括号时(…)就明白，这就是调用函数的信号。向前闪存( Flash forward ???)，每个函数都会返回一些东西（值，对象或undefined）。从函数返回的所有内容都会分配给变量 b。 但首先我们需要调用命名为 addTwo 的函数。JavaScript 将在其全局执行上下文内存中查找名为的变量 addTwo 。哦，它找到了一个，它在步骤2（或第2-5行）中定义。并且查看变量 addTwo 包含的函数定义。需要注意的是变量 a 作为参数传递给函数。JavaScript 在其全局执行上下文内存中搜索变量 a，找到它然后发现它的值是 3 并将该数字 3 作为参数传递给函数。然后准备执行该函数。 现在 执行上下文 将切换。创建一个新的 局部执行上下文 ，我们将其命名为“addTwo execution context”。 执行上下文 被推送到调用堆栈。我们在 局部执行上下文 中做的第一件事是什么？ 您可能会想说，“ ret 在 局部执行上下文 中声明了一个新变量”。但是这不是答案。正确的答案是，我们首先需要查看函数的参数。x 在本地执行上下文中声明了一个新变量。并且由于该值 3 作为参数传递，因此变量 x 被赋予数字 3。 下一步是：ret 在 局部执行上下文 中声明一个新变量。其值设置为undefined。（第3行） 仍然是第3行，需要进行加法。首先，我们需要 x 的值。JavaScript 将查找变量 x。它将首先查看 局部执行上下文 。它找到了一个变量 x 的值是3。第二个操作数就是数字2。将 addition（5）的结果赋给变量ret。 第4行。我们返回变量的内容 ret. 局部执行上下文 中的另一个查找。ret 包含值 5。该函数返回数字 5。功能结束。 第4-5行。功能结束。 局部执行上下文 被销毁。变量 x 和 ret 被销毁。它们不再存在。上下文弹出调用堆栈，返回值返回到调用上下文。在这种情况下，调用上下文是全局执行上下文，因为该函数addTwo是从全局执行上下文调用的。 现在我们在步骤4中选择我们停止的位置。返回的值（数字5）将分配给变量b。我们仍然在小程序的第6行。我不会详细介绍，但在第7行中，变量的内容b会在控制台中打印出来。在我们的例子中的数字5。对于一个非常简单的程序来说，这是一个非常冗长的解释，我们甚至还没有涉及到闭包。我保证会讲到那里。但首先我们需要再绕一两次。 命名空间(lexical scope)我们需要了解词法范围的某些方面。看一下下面的例子。 12345671：let val1 = 2 2：function multiplyThis（n）&#123; 3： let ret = n * val1 4： return ret 5：&#125; 6：let multiplied = multiplyThis（6）7：console.log（&apos;example of scope：&apos; ，multiplied） 这里的关注点是我们在 局部执行上下文 中有变量，在全局执行上下文中有变量。JavaScript 的一个复杂之处在于它如何查找变量。如果它在 局部执行上下文 中找不到变量，它将在其 调用上下文 中查找它。如果没有在其 调用上下文 中找到它。它会一直循环点查找, 直到它查看全局执行上下文。（如果它没有找到它，那就是undefined）。按照上面的例子，它将说明它。如果您了解空间(scope)的工作原理，则可以跳过此步骤。 val1 在全局执行上下文中声明一个新变量并为其分配数字2。 第2-5行。声明一个新变量 multiplyThis 并为其分配一个函数定义。 第6行。multiplied 在全局执行上下文中声明一个新变量。 multiplyThis 从全局执行上下文内存中检索变量并将其作为函数执行。将数字 6 作为参数传递。 新函数调用 = 新 执行上下文 。创建新的 局部执行上下文 。 在 局部执行上下文 中，声明一个变量 n 并为其分配数字 6。 第3行。在 局部执行上下文 中，声明一个变量 ret。 第3行（续）。用两个操作数执行乘法运算; 变量的内容为 n 和 val1。n 在 局部执行上下文 中查找变量。我们在第6步中声明了它。它的内容是数字6。val1 在 局部执行上下文 中查找变量。 局部执行上下文 没有标记的变量 val1。然后我们来检查 调用上下文 。 调用上下文 是全局执行上下文。让我们 val1 在全局执行上下文中寻找。它在第一行中定义。值是数字2。 第3行（续）。将两个操作数相乘并将其分配给 ret 变量。6 * 2 = 12. ret 现在是12。 返回 ret 变量。 局部执行上下文 及其变量 ret 和 n 会被销毁 。变量val1 不会被销毁，因为它是全局执行上下文的一部分。 返回第6行。在 调用上下文 中，将数字12分配给multiplied 变量。 最后在第7行，我们 multiplied 在控制台中显示变量的值。所以在这个例子中，我们需要记住一个函数可以访问在其 调用上下文 中定义的变量。这种现象的正式名称是命名空间(lexical scope)。 一个返回函数的函数在第一个示例中，函数 addTwo 返回一个数字。要记住的是之前函数可以返回任何内容。现在让我们来看一个返回函数的函数示例，因为这对理解闭包很重要。以下是我们要分析的示例。 1234567891011 1: let val = 7 2: function createAdder() &#123; 3: function addNumbers(a, b) &#123; 4: let ret = a + b 5: return ret 6: &#125; 7: return addNumbers 8: &#125; 9: let adder = createAdder()10: let sum = adder(val, 8)11: console.log(&apos;example of function returning a function: &apos;, sum) 让我们回来进行逐步细分。 第1行。我们val在全局执行上下文中声明一个变量，并为该7变量赋值。 第2-8行。我们声明一个createAdder在全局执行上下文中命名的变量，并为其分配一个函数定义。第3至7行描述了所述功能定义。和以前一样，在这一点上，我们并没有跳进那个功能。我们只是将函数定义存储到该变量（createAdder）中。 第9行。我们adder在全局执行上下文中声明一个名为的新变量。暂时undefined分配给adder。 仍然是第9行。我们看到括号(); 我们需要执行或调用函数。让我们查询全局执行上下文的内存并查找名为的变量createAdder。它是在第2步创建的。好吧，我们来称呼它。 调用一个函数。现在我们在第2行。创建了一个新的本地执行上下文。我们可以在新的 执行上下文 中创建局部变量。引擎将新上下文添加到调用堆栈。该函数没有参数，让我们直接进入它的主体。 仍然是3-6行。我们有一个新的函数声明。我们addNumbers在本地执行上下文中创建一个变量。这很重要。addNumbers仅存在于本地执行上下文中。我们将函数定义存储在名为的局部变量中addNumbers。 现在我们在第7行。我们返回变量的内容addNumbers。引擎查找名为的变量addNumbers并找到它。这是一个功能定义。很好，一个函数可以返回任何东西，包括函数定义。所以我们返回的定义addNumbers。第4行和第5行的括号之间的任何内容构成了函数定义。我们还从调用堆栈中删除了本地执行上下文。 在return，本地执行上下文被销毁。该addNumbers变量是没有更多的。函数定义仍然存在，它从函数返回并分配给变量adder; 这是我们在第3步中创建的变量。 现在我们在第10行。我们sum在全局执行上下文中定义一个新变量。临时任务是undefined。 我们需要接下来执行一个函数。哪个功能？在名为的变量中定义的函数adder。我们在全局执行环境中查找它，我们确实找到了它。这是一个带两个参数的函数。 让我们检索两个参数，这样我们就可以调用函数并传递正确的参数。第一个是val我们在步骤1中定义的变量，它表示数字7，第二个是数字8。 现在我们必须执行该功能。功能定义概述为第3-5行。创建新的本地执行上下文。在本地上下文中，创建了两个新变量：a和b。它们分别被赋值，7并且8因为那些是我们在上一步中传递给函数的参数。 第4行ret。声明了一个名为的新变量。它在本地执行上下文中声明。第4行。执行添加，我们在其中添加变量a的内容和变量的内容b。将addition（15）的结果赋给ret变量。 该ret变量从该函数返回。本地执行上下文被销毁，它从调用堆栈，变量中删除a，b并且ret不再存在。 返回的值将分配给sum我们在步骤9中定义的变量。 我们打印出sum控制台的值。正如预期的那样，控制台将打印15.我们真的经历了一堆箍。我想在这里说明几点。首先，函数定义可以存储在变量中，函数定义对程序是不可见的，直到被调用。其次，每次调用函数时，（临时）创建本地执行上下文。当函数完成时， 执行上下文 消失。函数在遇到return或关闭括号时完成}。 最后，闭包看看下一个代码，并试着弄清楚会发生什么。123456789101112131：function createCounter（）&#123; 2：let counter = 0 3：const myFunction = function（）&#123; 4：counter = counter + 1 5：return counter 6：&#125; 7：return myFunction 8：&#125; 9：const increment = createCounter（）10：const c1 = increment（）11：const c2 = increment（）12：const c3 = increment（）13：console.log（&apos;example increment&apos;，c1，c2，c3） 现在我们从之前的两个例子中得到了它，让我们按照我们期望它运行的方式执行此操作。 第1-8行。我们createCounter在全局执行上下文中创建一个新变量，并获得已分配的函数定义。 第9行。我们声明一个increment在全局执行上下文中命名的新变量。 第9行。我们需要调用createCounter函数并将其返回值increment赋给变量。 第1-8行。调用函数。创建新的本地执行上下文。 第2行。在本地执行上下文中，声明一个名为的新变量counter。编号0分配给counter。 3-6行。声明名为的新变量myFunction。该变量在本地执行上下文中声明。变量的内容是另一个函数定义。如第4和第5行所定义。 第7行。返回myFunction变量的内容。删除本地执行上下文。myFunction并且counter不再存在。控制返回到调用上下文。 第9行。在调用上下文中，全局执行上下文，返回的值createCounter被赋值给increment。变量增量现在包含一个函数定义。返回的函数定义createCounter。它不再被标记myFunction，但它的定义相同。在全球范围内，它被标记increment。 第10行。声明一个新变量（c1）。 第10行（续）。查找变量increment，它是一个函数，调用它。它包含从前面返回的函数定义，如第4-5行中所定义。 创建一个新的 执行上下文 。没有参数。开始执行该功能。 第4行counter = counter + 1。counter在本地执行上下文中查找值。我们刚刚创建了上下文，并且从不声明任何局部变量。让我们看看全局执行上下文。counter此处没有标记变量。Javascript会将其评估为counter = undefined + 1，声明一个标记的新局部变量counter并为其分配数字1，就像undefined它的类型一样0。 第5行。我们返回内容counter或数字1。我们销毁本地执行上下文和counter变量。 返回第10行。返回的值（1）被赋值给c1。 第11行。我们重复步骤10-14，也c2被分配1。 第12行。我们重复步骤10-14，也c3被分配1。 第13行。我们记录变量的内容c1，c2和c3。 亲自尝试一下，看看会发生什么。您会注意到它没有记录1，1并且1正如您在上面的解释中所期望的那样。相反，它是记录1，2和3。什么赋予了什么？ 不知何故，增量函数会记住该counter 值。那怎么样？ 是counter 全球执行环境的一部分吗？试试吧console.log(counter)，你会得到的undefined。所以那不是它。 也许，当你打电话时increment，它会以某种方式回到创建它的函数（createCounter）？怎么会这样呢？变量increment包含函数定义，而不是它来自何处。所以那不是它。 所以必须有另一种机制。关闭。我们终于得到了它，失踪的一块。 下面是它的工作原理。每当声明一个新函数并将其赋值给变量时，都会存储函数定义以及闭包。闭包包含创建函数时范围内的所有变量。它类似于背包。功能定义附带一个小背包。在它的包中，它存储了创建函数定义时范围内的所有变量。 所以我们上面的解释都是错误的，让我们再试一次，但这次是正确的。123456789101112131：function createCounter（）&#123; 2：let counter = 0 3：const myFunction = function（）&#123; 4：counter = counter + 1 5：return counter 6：&#125; 7：return myFunction 8：&#125; 9：const increment = createCounter（）10：const c1 = increment（）11：const c2 = increment（）12：const c3 = increment（）13：console.log（&apos;example increment&apos;，c1，c2，c3） 第1-8行。我们createCounter在全局执行上下文中创建一个新变量，并获得已分配的函数定义。与上面相同。 第9行。我们声明一个increment在全局执行上下文中命名的新变量。与上面相同。 第9行。我们需要调用createCounter函数并将其返回值increment赋给变量。与上面相同。 第1-8行。调用函数。创建新的本地执行上下文。与上面相同。 第2行。在本地执行上下文中，声明一个名为的新变量counter。编号0分配给counter。与上面相同。 3-6行。声明名为的新变量myFunction。该变量在本地执行上下文中声明。变量的内容是另一个函数定义。如第4行和第5行所定义。现在我们还创建一个闭包并将其作为函数定义的一部分包含在内。闭包含包含范围内的变量，在本例中为变量counter（值为0）。 第7行。返回myFunction变量的内容。删除本地执行上下文。myFunction并且counter不再存在。控制返回到调用上下文。所以我们返回函数定义及其闭包，背包中包含创建时范围内的变量。 第9行。在调用上下文中，全局执行上下文，返回的值createCounter被赋值给increment。变量增量现在包含一个函数定义（和闭包）。返回的函数定义createCounter。它不再被标记myFunction，但它的定义相同。在全球范围内，它被称为increment。 第10行。声明一个新变量（c1）。 第10行（续）。查找变量increment，它是一个函数，调用它。它包含从前面返回的函数定义，如第4-5行中所定义。（还有一个带变量的背包） 创建一个新的 执行上下文 。没有参数。开始执行该功能。 第4行counter = counter + 1。我们需要寻找变量counter。在我们查看本地或全局执行环境之前，让我们看看我们的背包。我们来检查关闭。瞧，闭包含一个名为的变量counter，其值为0。在第4行表达式之后，其值设置为1。它再次存放在背包里。闭包现在包含counter值为的变量1。 第5行。我们返回内容counter或数字1。我们破坏了本地执行上下文。 返回第10行。返回的值（1）被赋值给c1。 第11行。我们重复步骤10-14。这次，当我们查看闭包时，我们看到counter变量的值为1.它是在程序的第12步或第4行中设置的。它的值递增并存储2在增量函数的闭包中。并c2获得分配2。 第12行。我们重复步骤10-14，c3分配3。 第13行。我们记录变量的内容c1，c2和c3。 所以现在我们了解这是如何工作的。要记住的关键是当声明一个函数时，它包含一个函数定义和一个闭包。闭包是函数创建时范围内所有变量的集合。 您可能会问，任何函数是否都有闭包，甚至是在全局范围内创建的函数？答案是肯定的。在全局范围中创建的函数会创建一个闭包。但由于这些函数是在全局范围内创建的，因此它们可以访问全局范围内的所有变量。封闭概念并不真正相关。 当函数返回一个函数时，就是闭包的概念变得更加相关。返回的函数可以访问不在全局范围内的变量，但它们仅存在于其闭包中。 不是那么微不足道的关闭当你甚至没有注意到它时，有时会出现关闭。您可能已经看到了我们称之为部分应用程序的示例。如下面的代码。12345set c = 4 const addX = x =&gt; n =&gt; n + x const addThree = addX（3）let d = addThree（c）console.log（&apos;example partial application&apos;，d） 如果箭头函数抛出你，这是等效的。12345678910let c = 4 function addX（x）&#123; return function（n）&#123; return n + x &#125; &#125; const addThree = addX（3）let d = addThree（c）console.log（&apos;example partial application&apos;，d）我们声明了一个通用加法器函数addX，它接受一个参数（x）并返回另一个函数。 返回的函数也接受一个参数并将其添加到变量中x。 变量x是闭包的一部分。当变量addThree在本地上下文中声明时，它被赋予一个函数定义和一个闭包。闭包包含变量x。 所以现在当addThree调用并执行它时，它可以x从其闭包中获取变量，并且该变量n作为参数传递并且能够返回总和。 在此示例中，控制台将打印该号码7。 结论我永远记得关闭的方式是通过背包类比。当一个函数被创建并传递或从另一个函数返回时，它带有一个背包。并且在背包中是声明函数时范围内的所有变量。]]></content>
  </entry>
  <entry>
    <title><![CDATA[ElasticSearch 修改 mapping]]></title>
    <url>%2FElasticSearch%20%E4%BF%AE%E6%94%B9%20mapping.html</url>
    <content type="text"><![CDATA[https://www.elastic.co/blog/logstash_lesson_elasticsearch_mapping 12345678910111213141516171819POST imore-2018.07.25/doc/_search&#123; &quot;query&quot;:&#123;&quot;match_all&quot;: &#123;&#125;&#125;, &quot;aggs&quot;: &#123; &quot;e_terms&quot;: &#123; &quot;terms&quot;: &#123;&quot;field&quot;: &quot;e.keyword&quot;&#125;, &quot;aggs&quot;: &#123; &quot;f_terms&quot;: &#123; &quot;terms&quot;: &#123;&quot;field&quot;: &quot;f.keyword&quot;&#125;, &quot;aggs&quot;: &#123; &quot;g_terms&quot;: &#123; &quot;terms&quot;: &#123;&quot;field&quot;: &quot;g.keyword&quot;&#125; &#125; &#125; &#125; &#125; &#125; &#125;&#125;]]></content>
      <categories>
        <category>ELK</category>
      </categories>
      <tags>
        <tag>ELK</tag>
        <tag>ElasticSsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cluster_block_exception]]></title>
    <url>%2Fcluster-block-exception.html</url>
    <content type="text"><![CDATA[在导入数据的时候遇见了一个错误1retrying failed action with response code: 403 (&#123;&quot;type&quot;=&gt;&quot;cluster_block_exception&quot;, &quot;reason&quot;=&gt;&quot;blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];&quot;&#125;) 这是因为 read_only_allow_delete: false 被设置为 true 了, 只要把它设置回 false 就会继续导入数据.但是, 需要去查看设置为 true 的原因. 因为在硬盘占用达到 95% 的时候会自动设置为 true.这个时候如果设置回 false 过一段时间, 它也会设值为 true. 需要用户清除数据或者扩大硬盘大小才能继续.]]></content>
      <categories>
        <category>ELK</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[硬盘使用情况查看]]></title>
    <url>%2F%E7%A1%AC%E7%9B%98%E4%BD%BF%E7%94%A8%E6%83%85%E5%86%B5%E6%9F%A5%E7%9C%8B.html</url>
    <content type="text"><![CDATA[df命令是linux系统以磁盘分区为单位查看文件系统，可以加上参数查看磁盘剩余空间信息，命令格式：df -hl显示格式为：12345678910文件系统 容量 已用 可用 已用% 挂载点Filesystem Size Used Avail Use% Mounted on/dev/hda2 45G 19G 24G 44% //dev/hda1 494M 19M 450M 4% /boot/dev/hda6 4.9G 2.2G 2.5G 47% /home/dev/hda5 9.7G 2.9G 6.4G 31% /optnone 1009M 0 1009M 0% /dev/shm/dev/hda3 9.7G 7.2G 2.1G 78% /usr/local/dev/hdb2 75G 75G 0 100% //dev/hdb2 75G 75G 0 100% / 以上面的输出为例，表示的意思为： HD硬盘接口的第二个硬盘（b），第二个分区（2），容量是75G，用了75G，可用是0，因此利用率是100%， 被挂载到根分区目录上（/）。 下面是相关命令的解释：1234df -hl 查看磁盘剩余空间df -h 查看每个根路径的分区大小du -sh [目录名] 返回该目录的大小du -sm [文件夹] 返回该文件夹总M数 更多功能可以输入一下命令查看：12df --helpdu --help 查看linux文件目录的大小和文件夹包含的文件数 统计总数大小12345du -sh xmldb/du -sm * | sort -n //统计当前目录大小 并安大小 排序du -sk * | sort -ndu -sk * | grep guojf //看一个人的大小du -m | cut -d &quot;/&quot; -f 2 //看第二个/ 字符前的文字 查看此文件夹有多少文件 ///* 有多少文件123du xmldb/du xmldb/*/*/* |wc -l40752 解释：wc [-lmw]参数说明：-l :多少行；-m:多少字符；-w:多少字两个命令df 、du结合比较直观123df -h 查看整台服务器的硬盘使用情况cd / 进入根目录du -sh * 查看每个文件夹的大小 这样的组合可以快速定位大文件和分区满了]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Command</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK: ELK 配置]]></title>
    <url>%2FELK-ELK-%E9%85%8D%E7%BD%AE.html</url>
    <content type="text"><![CDATA[Elasticsearch 配置Elasticsearch 配置文件在 elasticsearch/config 文件夹下. 这个文件夹有两个配置文件 elasticsearch.yml 是配置不同模块的配置文件, logging.yml 是配置日志的配置文件. docker 映射配置文件12345678910111213141516/opt/kibana/config/kibana.yml # kibana 的配置文件/opt/logstash/config/logstash.yml # logstash 的配置文件/opt/elasticsearch/config/elasticsearch.yml # es 的配置文件/usr/share/elasticsearch/data # es 存储数据的位置 docker run -p 8001:5601 -p 8002:9200 -p 8003:9300 -p 8004:5044 \ -v /data/elk/logstash/conf.d:/etc/logstash/conf.d \ -v /data/elk/kibana/config/kibana.yml:/opt/kibana/config/kibana.yml \ -v /data/elk/logstash/config/logstash.yml:/opt/logstash/config/logstash.yml \ -v /data/elk/elasticsearch/config/elasticsearch.yml:/opt/elasticsearch/config/elasticsearch.yml \ -v /data/elk/elasticsearch/data:/usr/share/elasticsearch/data \ -v /data/elk/elasticsearch/log/:/var/lib/elasticsearch \ -v /data/elk/kibana/run_log/:/var/log/kibana/ \ -v /data/elk/logstash/run_log/:/var/log/logstash/ \ -v /data/elk/elasticsearch/run_log/:/var/log/elasticsearch/ \ -it --name elk sebp/elk LogStash 配置12345678910111213141516171819202122232425262728293031323334353637383940input &#123; beats &#123; port =&gt; 5044 ssl =&gt; true ssl_certificate =&gt; &quot;/etc/pki/tls/certs/logstash-beats.crt&quot; ssl_key =&gt; &quot;/etc/pki/tls/private/logstash-beats.key&quot; &#125;&#125;filter &#123; grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;SYSLOGTIMESTAMP:syslog_timestamp&#125; %&#123;SYSLOGHOST:syslog_hostname&#125; %&#123;DATA:syslog_program&#125;(?:\[%&#123;POSINT:syslog_pid&#125;\])?: %&#123;GREEDYDATA:syslog_message&#125;&quot; &#125; add_field =&gt; [ &quot;received_at&quot;, &quot;%&#123;@timestamp&#125;&quot; ] add_field =&gt; [ &quot;received_from&quot;, &quot;%&#123;host&#125;&quot; ] &#125; syslog_pri &#123; &#125; date &#123; match =&gt; [ &quot;syslog_timestamp&quot;, &quot;MMM d HH:mm:ss&quot;, &quot;MMM dd HH:mm:ss&quot; ] &#125;&#125;filter &#123; grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;NGINXACCESS&#125;&quot; &#125; &#125;&#125;filter &#123; json &#123; source =&gt; &quot;message&quot; #target =&gt; &quot;doc&quot; #remove_field =&gt; [&quot;message&quot;] &#125; &#125;output &#123; elasticsearch &#123; hosts =&gt; [&quot;localhost&quot;] manage_template =&gt; false index =&gt; &quot;%&#123;[@metadata][beat]&#125;-%&#123;+YYYY.MM.dd&#125;&quot; document_type =&gt; &quot;%&#123;[@metadata][type]&#125;&quot; &#125;&#125; 其他示例配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788# ======================== Elasticsearch Configuration =========================## NOTE: Elasticsearch comes with reasonable defaults for most settings.# Before you set out to tweak and tune the configuration, make sure you# understand what are you trying to accomplish and the consequences.## The primary way of configuring a node is via this file. This template lists# the most important settings you may want to configure for a production cluster.## Please consult the documentation for further information on configuration options:# https://www.elastic.co/guide/en/elasticsearch/reference/index.html## ---------------------------------- Cluster -----------------------------------## Use a descriptive name for your cluster:## cluster.name: aoemo## ------------------------------------ Node ------------------------------------## Use a descriptive name for the node:## node.name: node-1## Add custom attributes to the node:##node.attr.rack: r1## ----------------------------------- Paths ------------------------------------## Path to directory where to store the data (separate multiple locations by comma):#path.data: /usr/share/elasticsearch/data## Path to log files:#path.logs: /var/lib/elasticsearch## ----------------------------------- Memory -----------------------------------## Lock the memory on startup:##bootstrap.memory_lock: true## Make sure that the heap size is set to about half the memory available# on the system and that the owner of the process is allowed to use this# limit.## Elasticsearch performs poorly when the system is swapping the memory.## ---------------------------------- Network -----------------------------------## Set the bind address to a specific IP (IPv4 or IPv6):##network.host: 192.168.0.1## Set a custom port for HTTP:##http.port: 9200## For more information, consult the network module documentation.## --------------------------------- Discovery ----------------------------------## Pass an initial list of hosts to perform discovery when new node is started:# The default list of hosts is [&quot;127.0.0.1&quot;, &quot;[::1]&quot;]##discovery.zen.ping.unicast.hosts: [&quot;host1&quot;, &quot;host2&quot;]## Prevent the &quot;split brain&quot; by configuring the majority of nodes (total number of master-eligible nodes / 2 + 1):##discovery.zen.minimum_master_nodes:## For more information, consult the zen discovery module documentation.## ---------------------------------- Gateway -----------------------------------## Block initial recovery after a full cluster restart until N nodes are started:##gateway.recover_after_nodes: 3## For more information, consult the gateway module documentation.## ---------------------------------- Various -----------------------------------## Require explicit names when deleting indices:##action.destructive_requires_name: true 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101# Default Kibana 5 file from https://github.com/elastic/kibana/blob/master/config/kibana.yml## Kibana is served by a back end server. This setting specifies the port to use.#server.port: 5601# Specifies the address to which the Kibana server will bind. IP addresses and host names are both valid values.# The default is &apos;localhost&apos;, which usually means remote machines will not be able to connect.# To allow connections from remote users, set this parameter to a non-loopback address.server.host: &quot;0.0.0.0&quot;# Enables you to specify a path to mount Kibana at if you are running behind a proxy. This only affects# the URLs generated by Kibana, your proxy is expected to remove the basePath value before forwarding requests# to Kibana. This setting cannot end in a slash.#server.basePath: &quot;&quot;# The maximum payload size in bytes for incoming server requests.#server.maxPayloadBytes: 1048576# The Kibana server&apos;s name. This is used for display purposes.#server.name: &quot;your-hostname&quot;# The URL of the Elasticsearch instance to use for all your queries.#elasticsearch.url: &quot;http://localhost:9200&quot;# When this setting’s value is true Kibana uses the hostname specified in the server.host# setting. When the value of this setting is false, Kibana uses the hostname of the host# that connects to this Kibana instance.#elasticsearch.preserveHost: true# Kibana uses an index in Elasticsearch to store saved searches, visualizations and# dashboards. Kibana creates a new index if the index doesn’t already exist.#kibana.index: &quot;.kibana&quot;# The default application to load.#kibana.defaultAppId: &quot;discover&quot;# If your Elasticsearch is protected with basic authentication, these settings provide# the username and password that the Kibana server uses to perform maintenance on the Kibana# index at startup. Your Kibana users still need to authenticate with Elasticsearch, which# is proxied through the Kibana server.elasticsearch.username: &quot;elastic&quot;elasticsearch.password: &quot;changeme&quot;# Paths to the PEM-format SSL certificate and SSL key files, respectively. These# files enable SSL for outgoing requests from the Kibana server to the browser.#server.ssl.cert: /path/to/your/server.crt#server.ssl.key: /path/to/your/server.key# Optional settings that provide the paths to the PEM-format SSL certificate and key files.# These files validate that your Elasticsearch backend uses the same key files.#elasticsearch.ssl.cert: /path/to/your/client.crt#elasticsearch.ssl.key: /path/to/your/client.key# Optional setting that enables you to specify a path to the PEM file for the certificate# authority for your Elasticsearch instance.#elasticsearch.ssl.ca: /path/to/your/CA.pem# To disregard the validity of SSL certificates, change this setting’s value to false.#elasticsearch.ssl.verify: true# Time in milliseconds to wait for Elasticsearch to respond to pings. Defaults to the value of# the elasticsearch.requestTimeout setting.#elasticsearch.pingTimeout: 1500# Time in milliseconds to wait for responses from the back end or Elasticsearch. This value# must be a positive integer.#elasticsearch.requestTimeout: 30000# List of Kibana client-side headers to send to Elasticsearch. To send *no* client-side# headers, set this value to [] (an empty list).#elasticsearch.requestHeadersWhitelist: [ authorization ]# Header names and values that are sent to Elasticsearch. Any custom headers cannot be overwritten# by client-side headers, regardless of the elasticsearch.requestHeadersWhitelist configuration.#elasticsearch.customHeaders: &#123;&#125;# Time in milliseconds for Elasticsearch to wait for responses from shards. Set to 0 to disable.#elasticsearch.shardTimeout: 0# Time in milliseconds to wait for Elasticsearch at Kibana startup before retrying.#elasticsearch.startupTimeout: 5000# Specifies the path where Kibana creates the process ID file.#pid.file: /var/run/kibana.pid# Enables you specify a file where Kibana stores log output.#logging.dest: stdout# Set the value of this setting to true to suppress all logging output.#logging.silent: false# Set the value of this setting to true to suppress all logging output other than error messages.#logging.quiet: false# Set the value of this setting to true to log all events, including system usage information# and all requests.#logging.verbose: false# Set the interval in milliseconds to sample system and process performance# metrics. Minimum is 100ms. Defaults to 5000.#ops.interval: 5000 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246# Settings file in YAML## Settings can be specified either in hierarchical form, e.g.:## pipeline:# batch:# size: 125# delay: 5## Or as flat keys:## pipeline.batch.size: 125# pipeline.batch.delay: 5## ------------ Node identity ------------## Use a descriptive name for the node:## node.name: test## If omitted the node name will default to the machine&apos;s host name## ------------ Data path ------------------## Which directory should be used by logstash and its plugins# for any persistent needs. Defaults to LOGSTASH_HOME/data## path.data:## ------------ Pipeline Settings --------------## The ID of the pipeline.## pipeline.id: main## Set the number of workers that will, in parallel, execute the filters+outputs# stage of the pipeline.## This defaults to the number of the host&apos;s CPU cores.## pipeline.workers: 2## How many events to retrieve from inputs before sending to filters+workers## pipeline.batch.size: 125## How long to wait in milliseconds while polling for the next event# before dispatching an undersized batch to filters+outputs## pipeline.batch.delay: 50## Force Logstash to exit during shutdown even if there are still inflight# events in memory. By default, logstash will refuse to quit until all# received events have been pushed to the outputs.## WARNING: enabling this can lead to data loss during shutdown## pipeline.unsafe_shutdown: false## ------------ Pipeline Configuration Settings --------------## Where to fetch the pipeline configuration for the main pipeline## path.config:## Pipeline configuration string for the main pipeline## config.string:## At startup, test if the configuration is valid and exit (dry run)## config.test_and_exit: false## Periodically check if the configuration has changed and reload the pipeline# This can also be triggered manually through the SIGHUP signal## config.reload.automatic: false## How often to check if the pipeline configuration has changed (in seconds)## config.reload.interval: 3s## Show fully compiled configuration as debug log message# NOTE: --log.level must be &apos;debug&apos;## config.debug: false## When enabled, process escaped characters such as \n and \&quot; in strings in the# pipeline configuration files.## config.support_escapes: false## ------------ Module Settings ---------------# Define modules here. Modules definitions must be defined as an array.# The simple way to see this is to prepend each `name` with a `-`, and keep# all associated variables under the `name` they are associated with, and# above the next, like this:## modules:# - name: MODULE_NAME# var.PLUGINTYPE1.PLUGINNAME1.KEY1: VALUE# var.PLUGINTYPE1.PLUGINNAME1.KEY2: VALUE# var.PLUGINTYPE2.PLUGINNAME1.KEY1: VALUE# var.PLUGINTYPE3.PLUGINNAME3.KEY1: VALUE## Module variable names must be in the format of## var.PLUGIN_TYPE.PLUGIN_NAME.KEY## modules:## ------------ Cloud Settings ---------------# Define Elastic Cloud settings here.# Format of cloud.id is a base64 value e.g. dXMtZWFzdC0xLmF3cy5mb3VuZC5pbyRub3RhcmVhbCRpZGVudGlmaWVy# and it may have an label prefix e.g. staging:dXMtZ...# This will overwrite &apos;var.elasticsearch.hosts&apos; and &apos;var.kibana.host&apos;# cloud.id: &lt;identifier&gt;## Format of cloud.auth is: &lt;user&gt;:&lt;pass&gt;# This is optional# If supplied this will overwrite &apos;var.elasticsearch.username&apos; and &apos;var.elasticsearch.password&apos;# If supplied this will overwrite &apos;var.kibana.username&apos; and &apos;var.kibana.password&apos;# cloud.auth: elastic:&lt;password&gt;## ------------ Queuing Settings --------------## Internal queuing model, &quot;memory&quot; for legacy in-memory based queuing and# &quot;persisted&quot; for disk-based acked queueing. Defaults is memory## queue.type: memory## If using queue.type: persisted, the directory path where the data files will be stored.# Default is path.data/queue## path.queue:## If using queue.type: persisted, the page data files size. The queue data consists of# append-only data files separated into pages. Default is 64mb## queue.page_capacity: 64mb## If using queue.type: persisted, the maximum number of unread events in the queue.# Default is 0 (unlimited)## queue.max_events: 0## If using queue.type: persisted, the total capacity of the queue in number of bytes.# If you would like more unacked events to be buffered in Logstash, you can increase the# capacity using this setting. Please make sure your disk drive has capacity greater than# the size specified here. If both max_bytes and max_events are specified, Logstash will pick# whichever criteria is reached first# Default is 1024mb or 1gb## queue.max_bytes: 1024mb## If using queue.type: persisted, the maximum number of acked events before forcing a checkpoint# Default is 1024, 0 for unlimited## queue.checkpoint.acks: 1024## If using queue.type: persisted, the maximum number of written events before forcing a checkpoint# Default is 1024, 0 for unlimited## queue.checkpoint.writes: 1024## If using queue.type: persisted, the interval in milliseconds when a checkpoint is forced on the head page# Default is 1000, 0 for no periodic checkpoint.## queue.checkpoint.interval: 1000## ------------ Dead-Letter Queue Settings --------------# Flag to turn on dead-letter queue.## dead_letter_queue.enable: false# If using dead_letter_queue.enable: true, the maximum size of each dead letter queue. Entries# will be dropped if they would increase the size of the dead letter queue beyond this setting.# Default is 1024mb# dead_letter_queue.max_bytes: 1024mb# If using dead_letter_queue.enable: true, the directory path where the data files will be stored.# Default is path.data/dead_letter_queue## path.dead_letter_queue:## ------------ Metrics Settings --------------## Bind address for the metrics REST endpoint## http.host: &quot;127.0.0.1&quot;## Bind port for the metrics REST endpoint, this option also accept a range# (9600-9700) and logstash will pick up the first available ports.## http.port: 9600-9700## ------------ Debugging Settings --------------## Options for log.level:# * fatal# * error# * warn# * info (default)# * debug# * trace## log.level: info# path.logs:## ------------ Other Settings --------------## Where to find custom plugins# path.plugins: []## ------------ X-Pack Settings (not applicable for OSS build)--------------## X-Pack Monitoring# https://www.elastic.co/guide/en/logstash/current/monitoring-logstash.html#xpack.monitoring.enabled: false#xpack.monitoring.elasticsearch.username: logstash_system#xpack.monitoring.elasticsearch.password: password#xpack.monitoring.elasticsearch.url: [&quot;https://es1:9200&quot;, &quot;https://es2:9200&quot;]#xpack.monitoring.elasticsearch.ssl.ca: [ &quot;/path/to/ca.crt&quot; ]#xpack.monitoring.elasticsearch.ssl.truststore.path: path/to/file#xpack.monitoring.elasticsearch.ssl.truststore.password: password#xpack.monitoring.elasticsearch.ssl.keystore.path: /path/to/file#xpack.monitoring.elasticsearch.ssl.keystore.password: password#xpack.monitoring.elasticsearch.ssl.verification_mode: certificate#xpack.monitoring.elasticsearch.sniffing: false#xpack.monitoring.collection.interval: 10s#xpack.monitoring.collection.pipeline.details.enabled: true## X-Pack Management# https://www.elastic.co/guide/en/logstash/current/logstash-centralized-pipeline-management.html#xpack.management.enabled: false#xpack.management.pipeline.id: [&quot;main&quot;, &quot;apache_logs&quot;]#xpack.management.elasticsearch.username: logstash_admin_user#xpack.management.elasticsearch.password: password#xpack.management.elasticsearch.url: [&quot;https://es1:9200&quot;, &quot;https://es2:9200&quot;]#xpack.management.elasticsearch.ssl.ca: [ &quot;/path/to/ca.crt&quot; ]#xpack.management.elasticsearch.ssl.truststore.path: /path/to/file#xpack.management.elasticsearch.ssl.truststore.password: password#xpack.management.elasticsearch.ssl.keystore.path: /path/to/file#xpack.management.elasticsearch.ssl.keystore.password: password#xpack.management.elasticsearch.sniffing: false#xpack.management.logstash.poll_interval: 5s 12345678910docker run -p 8001:5601 -p 8002:9200 -p 8003:9300 -p 8004:5044 \-v /data/elk/logstash/conf.d:/etc/logstash/conf.d \-v /data/elk/kibana/config/kibana.yml:/opt/kibana/config/kibana.yml \-v /data/elk/logstash/config/logstash.yml:/opt/logstash/config/logstash.yml \-v /data/elk/elasticsearch/config/elasticsearch.yml:/opt/elasticsearch/config/elasticsearch.yml \-v /data/elk/elasticsearch/data:/usr/share/elasticsearch/data \-v /data/elk/elasticsearch/log/:/var/lib/elasticsearch \-v /data/elk/kibana/run_log/:/var/log/kibana/ \-v /data/elk/logstash/run_log/:/var/log/logstash/ \-v /data/elk/elasticsearch/run_log/:/var/log/elasticsearch/ -it --name elk sebp/elk]]></content>
      <categories>
        <category>ELK</category>
      </categories>
      <tags>
        <tag>ELK</tag>
        <tag>ElasticSsearch</tag>
        <tag>Kibana</tag>
        <tag>LogStash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK: 使用 Docker 搭建 ELK 环境]]></title>
    <url>%2FELK-%E4%BD%BF%E7%94%A8-Docker-%E6%90%AD%E5%BB%BA-ELK-%E7%8E%AF%E5%A2%83.html</url>
    <content type="text"><![CDATA[​ 这里使用 Docker 直接搭建 ELK 环境, 因为 Docker 有第三方提供了 elk 的包, 减少了配置量.当然也可以用 ELK提供的官方 Docker 包或者直接安装, 但是因为工作需要就那么折腾了. Docker 安装 Docker 官方安装教程 https://docs.docker.com/v17.09/engine/installation/linux/docker-ce/centos/#prerequisites 123456789101112131415161718192021# 更新yum update# 删除旧版本避免冲突sudo yum remove docker \ docker-common \ docker-selinux \ docker-engine# 安装依赖sudo yum install -y yum-utils \ device-mapper-persistent-data \ lvm2# 安装 Docker 的 yum 源sudo yum-config-manager \ --add-repo \ https://download.docker.com/linux/centos/docker-ce.repo# 安装 Dockersudo yum install docker-ce# 开启 Dockersudo systemctl start docker# 开启 Dockerdocker info 这样 Docker 就安装好了, 一般不会遇到什么问题.需要注意的是这是 CentOS 的安装顺序, 其他系统参考官方教程. ELK 安装 ELK Docker 文档 http://elk-docker.readthedocs.io/ 安装 ELK Docker 镜像 12345678docker pull sebp/elkdocker run -p 5001:5601 -p 9200:9200 -p 5044:5044 -p 9300:9300 \ -v /data/elk/conf.d:/etc/logstash/conf.d -it --name elk sebp/elk# 这个包直接 run 就好了, 需要注意的是端口要映射出来, 如果需要修改配置就要映射配置文件.# 配置文件文件夹在文档中能找到, 相关配置也在里面.# 5601 -&gt; Kibana# 5044 -&gt; Logstash# 9200, 9300 -&gt; Elasticsearch 在文档里面提到一个先决条件, 就是 max_map_count 要大于 262144. Linux 设置 max_map_count 1234# 查看设置的 max_map_count 是多少sysctl vm.max_map_count# 设置 max_map_count 大于300000sysctl -w vm.max_map_count=300000 注意, 必须在主机上更改限制; 不能在容器内更改. Docker for Mac 设置 max_map_count在启动容器时设置环境变量 -e MAX_MAP_COUNT=300000如果没有问题就已经装好了, 可以通过 Kibana 和 Elasticsearch:9200 连接查看是否安装完成.]]></content>
      <categories>
        <category>ELK</category>
      </categories>
      <tags>
        <tag>ELK</tag>
        <tag>Elasticsearch</tag>
        <tag>Logstash</tag>
        <tag>Kibana</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[流畅的Python]]></title>
    <url>%2F%E6%B5%81%E7%95%85%E7%9A%84python.html</url>
    <content type="text"><![CDATA[流畅的python阅读笔记，流畅的python主要是讲了python的进阶特性。 第一章 Python数据模型 在 Python 中使用双下划线开头，双下划线结尾的方法就是 Python 的特殊方法。Python 会在碰到特殊句法的时候，会使用特殊方法去执行一些对象操作。这些特殊方法能让对象支持这些操作： 迭代， 集合类， 属性访问， 运算符重载， 函数和方法的调用， 对象的创建和销毁， 字符串表示形式和格式化， 管理上下文。 这些特殊方法的存在是为了被 Python 解释器调用的, 并不需要自己去调用它们. 即 没有 xxx.len() 这种写法, 而是应该使用 len(xxx). 在执行len(xxx) 的时候, 如果 xxx 是一个自定义的类对象, 那么 Python 解释器会去调用 len 方法. 而如果是 Python 内置的数据类型, 如 list, str 等, 那么 CPython 会直接返回 PyVarObject 里等 ob_size 属性. PyVarObject 是表示内存中长度可变的内置对象的C语言结构体, 这样会比调用方法更快. 这些特殊方法的调用通常是隐式的, 如 for i in x 这个语句调用的是 iter(x), 而这个 iter(x) 函数是调用的 x.iter() 方法. 特殊方法一览: 与运算符无关的特殊方法 字符串表示形式 __repr__ __str__ __format__ __bytes__ 数值转换 __abs__ __bool__ __complex__ __int__ __float__ __hash__ __index__ 集合模拟 __len__ __getitem__ __setitem__ __delitem__ __contains__ 迭代枚举 __iter__ __reversed__ __next__ 可调用模拟 __call__ 上下文管理 __enter__ __exit__ 实力创建和销毁 __new__ __init__ __del__ 属性管理 __getattr__ __getattribute__ __setattr__ __delatr__ __dir__ 属性描述符 __get__ __set__ __delete__ 和类相关的服务 __prepare__ __instancecheck__ __subclasscheck__ 与运算符相关的特殊方法 一元运算符 __neg__ __pos__ __abs__ 比较运算符 __lt__ __le__ __eq__ __ne__ __gt__ __ge__3. 算术运算符 __add__ __sub__ __mul__ __truediv__ __floordiv__ __mod__ __divmod__ __pow__ __round__ 反向运算符 __radd__ __rsub__ __rmul__ __rtruediv__ __rfloordiv__ __rmod__ __rdivmod__ __rpow__ 增量赋值算术运算符 __iadd__ __isub__ __imul__ __itruediv__ __ifloordiv__ __imod__ __ipow__ 位运算符 __invert__ __lshift__ __rshift__ __and__ __or__ __xor__ 反向位运算符 __rlshift__ __rrshift__ __rand__ ____rxor__ __ror__ 增量赋值位运算符 __ilshift__ __irshift__ __iand__ __ixor__ __ior__]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python Web开发测试驱动方法 笔记]]></title>
    <url>%2FPython-Web%E5%BC%80%E5%8F%91%E6%B5%8B%E8%AF%95%E9%A9%B1%E5%8A%A8%E6%96%B9%E6%B3%95%E7%AC%94%E8%AE%B0.html</url>
    <content type="text"><![CDATA[Python Web开发测试驱动方法的笔记django version: 1.11.7Python version: 3.6.2 第一部分 (第 1~6章 ): 基础知识第 1 章 功能测试协助安装Django测试山羊: “先测试,先测试,先测试”(重要的事说三遍)测试山羊: “没有测试什么也别做”这一章主要讲的是编写一个简单的测试查看Django是否安装正确,没有什么问题. 第 2 章 使用unittest模块扩展功能测试注释书中有一部分说到了注释.注释是有用的, 可以添加上下文,说明代码的目的,但是简单而重复的注释是毫无意义的.而且有一定风险,如果更新了代码后没有修改注释,会误导别人.例如:12# 把wibble的值增加 1wibble += 1 unittest模块 以test_开头的方法都是测试方法 测试方法的名称应该有意义 setUp和tearDown在该测试类的各个测试方法运行前和运行后执行 预期失败,应该预期测试方法的失败和失败方式 12345678910111213141516class XXTest(unittest.TestCase): def setUp(self): &apos;&apos;&apos;测试开始前执行&apos;&apos;&apos; self.browser = webdriver.Chrome() # 设置浏览器驱动 self.browser.implicitly_wait(3) # 隐式等待,在页面加载的时候让Selenium先等待 def tearDown(self): &apos;&apos;&apos;测试结束后执行&apos;&apos;&apos; self.browser.quit() # 设置退出浏览器 def testxxx(self): self.asserIn(&apos;XX&apos;, self.browser.title) # 测试浏览器标题是不是包含XXif __name__ == &apos;main&apos;: # 启动unittest测试程序,禁止抛出ResourceWarning异常 unittest.main(warnings=&apos;ignore&apos;) 第 3 章 使用单元测试测试简单的首页单元测试和功能测试的区别单元测试: 站在程序员的角度从内部测试应用功能测试: 站在用户的角度从外部测试应用 单元测试和功能测试的工作流程 先写功能测试, 从用户的角度描述应用的新功能 功能测试失败后,想办法编写代码让它通过(至少通过当前失败).使用一个或多个单元测试定义希望代码实现的效果,尽量覆盖每一行代码(至少一个) 单元测试失败后,写最少的应用代码让单元测试通过.直到功能测试有进展. 再次运行功能测试,然后根据新的测试结果编写新的单元测试和代码. 单元测试代码123456789101112131415161718192021222324# tests.pyclass HomePageTest(TestCase): def test_root_page_resolve(self): &quot;&quot;&quot;路径解析测试&quot;&quot;&quot; found = resolve(&apos;/&apos;) self.assertEqual(found.func, home_page) def test_home_page_returns_html(self): &quot;&quot;&quot;页面HTML解析&quot;&quot;&quot; request = HttpRequest() response = home_page(request) self.assertTrue(response.content.startswith(b&apos;&lt;html&gt;&apos;)) self.assertIn(b&apos;&lt;title&gt;To-Do lists&lt;/title&gt;&apos;, response.content) self.assertTrue(response.content.endswith(b&apos;&lt;/html&gt;&apos;))# lists/views.pydef home_page(request): return HttpResponse(&apos;&lt;html&gt;&lt;title&gt;To-Do lists&lt;/title&gt;&lt;/html&gt;)# superlists/urls.pyurlpatterns = [ url(r&apos;^admin/&apos;, admin.site.urls), url(r&apos;^$&apos;, view=views.home_page, name=&apos;home_page&apos;),] 单元测试时的问题在django 1.11.7中resolve的导入是1from django.urls import resolve resolve()中的path路径是在urls的路径加根目录1234found = resolve(&apos;/lists/&apos;)urls:url(r&apos;^lists/&apos;, view=views.home_page, name=&apos;home_page&apos;), 第 4 章 编写这些测试有什么用 测试有点多了?是不是太琐细了?我们并不是大神,也不是大牛,我们没办法避免错误,哪怕是大神可能也会出现简单的错误.TDD可以记录我们编码的进程,让我们不会反复的犯同一个错误.测试可能会很简单,但是有占位作用,当函数变复杂后就可能没那么容易测试了.在学习新框架的时候TDD也能帮助学习,排除错误. 123456def test_home_page_returns_html(self): &quot;&quot;&quot;页面HTML解析&quot;&quot;&quot; request = HttpRequest() response = home_page(request) expected_html = render_to_string(&apos;home.html&apos;) self.assertEqual(response.content.decode(), expected_html) 第 5 章 保存用户输入单元测试规则 不测试常量 assert语句123assertIn(xx, yy) yy中有没有xxassertEqual(xx,yy) xx和yy是不是一样assertTrue(xx) xx结果是不是True find_element_by 语句1234find_element_by_id(xx)find_element_by_tag_name(xx)find_elements_by_tag_name(xx)]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Django</tag>
        <tag>TDD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在aws 创建git 仓库]]></title>
    <url>%2F%E5%9C%A8aws-%E5%88%9B%E5%BB%BAgit-%E4%BB%93%E5%BA%93.html</url>
    <content type="text"><![CDATA[在aws上创建git仓库 在本地创建ssh公钥和私钥1ssh-keygen -t rsa -C &quot;xxx&quot; 在aws创建authortized_keys文件存放刚才生成的公钥。1234cd ~mkdir .ssh &amp;&amp; cd .sshtouch authorized_keysvi authorized_keys 创建git仓库12mkdir 仓库名称 &amp;&amp; cd 仓库名称git init --bare]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>aws</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 存储过程实例]]></title>
    <url>%2FMySQL-%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B%E5%AE%9E%E4%BE%8B.html</url>
    <content type="text"><![CDATA[MySQL 存储过程的一些例子,添加了一些注释 1. 存储过程存储过程11234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374CREATE PROCEDURE `SP_eco_stat`(IN report_type VARCHAR(100), IN start_datetime DATETIME, IN end_datetime DATETIME) # 存储过程名称（传入参数） COMMENT &apos;计算经济系统数据&apos; # 备注信息BEGIN # 存储过程开始 DECLARE `from` VARCHAR(100); #变量声明，要在前面 DECLARE `detail` VARCHAR(100); DECLARE `country` VARCHAR(100); DECLARE `change` VARCHAR(100); DECLARE `count` VARCHAR(100); DECLARE `user` VARCHAR(100); DECLARE `stop_flag` INT DEFAULT 0; # DEFAULT设置默认值，没有则为null DECLARE `date` DATE; DECLARE _Cursor CURSOR FOR SELECT # 声明光标 XX 光标名 XX a.`from` AS `from`, a.detail AS `detail`, a.country AS `country`, SUM(a.`change`) AS `change`, SUM(1) AS `count`, count(DISTINCT (a.uid)) AS `user` FROM credits a WHERE a.`time` BETWEEN start_datetime AND end_datetime AND a.`change` &gt; 0 GROUP BY a.`from`, a.`change`, a.country; DECLARE CONTINUE HANDLER FOR SQLSTATE &apos;02000&apos; SET stop_flag = 1; # 声明停止时stop_flag=1 SET `date` = CURDATE() + INTERVAL -(1) DAY; # 变量赋值 # 调试开关 SET @__logCallDebug = 1; CALL SP_LogCall(&apos;SP_eco_stat&apos;, # 调用存储过程 CONCAT_WS(&apos;,&apos;, QUOTE(report_type), QUOTE(start_datetime), QUOTE(end_datetime)), &apos;begin...&apos;); OPEN _Cursor; #打开光标 FETCH _Cursor INTO `from`, `detail`, `country`, `change`, `count`, `user`; # 调用光标并赋值 WHILE `stop_flag`&lt;&gt;1 DO # while循环 IF `country` IS NULL # if 判断 THEN SET `country` = &apos;&apos;; END IF; IF `change` IS NULL THEN SET `change` = &apos;&apos;; END IF; IF `detail` IS NULL THEN SET `detail` = &apos;&apos;; END IF; IF `from` IS NULL THEN SET `from` = &apos;&apos;; END IF; IF `count` IS NULL THEN SET `count` = &apos;&apos;; END IF; REPLACE INTO day_amounts(type1, type2, type3, type4, type5, DATE, amount) VALUES (report_type, `from`, `detail`, `country`, &apos;change&apos;, `date`, `change`), (report_type, `from`, `detail`, `country`, &apos;count&apos;, `date`, `count`), (report_type, `from`, `detail`, `country`, &apos;user&apos;, `date`, `user`); # INSERT INTO的强化版，如果有存在相同的主键时对该行进行更新 FETCH _Cursor INTO `from`, `detail`, `country`, `change`, `count`, `user`; END WHILE;CLOSE _Cursor; # 关闭光标CALL SP_LogCallDebug(&apos;end.&apos;);END # 存储过程结束 存储过程21234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192CREATE PROCEDURE SP_day_n_retention(IN calcdate_offset INT) COMMENT &apos;日留存计算&apos; BEGIN DECLARE yesterday DATE; # 调试开关 SET @__logCallDebug = 1; CALL SP_LogCall(&apos;SP_day_n_retention&apos;, CONCAT_WS(&apos;,&apos;, calcdate_offset), &apos;begin...&apos;); # day0安装 CALL SP_LogCallDebug(&apos;day0...&apos;); SET yesterday = adddate(date(NOW()), INTERVAL calcdate_offset DAY); # 获取当前【输入数字】天前的时间 date(NOW()) 现在时间 adddate 【DATE_ADD()的同义词】 获取【输入数字】天前的时间 # 安装量(去重) SET @_install_user_count = ( SELECT amount FROM day_amounts WHERE type1 = &apos;user&apos; AND type3 = &apos;new&apos; AND date BETWEEN CONCAT(yesterday, &apos; 00:00:00&apos;) AND CONCAT(yesterday, &apos; 23:59:59&apos;) # BETWEEN 多少和多少之间 CONCAT 连接字符串 ); # 插入或者更新day0 REPLACE INTO day_amounts ( type1, type2, type3, type4, type5, date, amount ) VALUES ( &apos;user&apos;, &apos; &apos;, &apos;retention&apos;, &apos; &apos;, &apos;day0&apos;, yesterday, @_install_user_count ); IF calcdate_offset &lt; 0 # 判断【输入数字】是否小于0 THEN BEGIN # exec执行错误 DECLARE errStr VARCHAR(10240); DROP TABLE IF EXISTS tmp_uuid; # 如果临时表存在则删除 CREATE TEMPORARY TABLE tmp_uuid ( # 创建临时表，只在当前连接有效 uuid VARCHAR(64) NOT NULL, PRIMARY KEY (uuid) ) ENGINE = MYISAM # 数据库存储引擎 和InnoDB相比更注重性能但功能也较少 CHARACTER SET latin1 COLLATE latin1_general_ci; INSERT tmp_uuid SELECT a.uid FROM users_active a WHERE a.act_time BETWEEN CONCAT(yesterday, &apos; 00:00:00&apos;) AND CONCAT(yesterday, &apos; 23:59:59&apos;); SET @days = &apos;1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,35,42,49,56,60,63,70,77,84,90&apos;; WHILE CHAR_LENGTH(@days) &gt; 0 DO # while 循环 SET @dayN = SUBSTRING_INDEX(@days, &apos;,&apos;, 1); # 截取在第一个【,】之前的字符 CALL SP_LogCallDebug(concat(&apos;day&apos;, @dayN, &apos;...&apos;)); # 日期偏移(例如: day1 = 1, day2 = 2, ...) SET @_dayOffset = (SELECT -CAST(@dayN AS SIGNED)); # CAST 获取一个类型的值并产生另一个类型的值 还有CONVERT(value, type) # 在用户表和日志表里找N天前安装的用户的留存量 DROP TEMPORARY TABLE IF EXISTS day_n_retention; SET @_execStr = CONCAT( &apos;REPLACE INTO day_amounts(type1,type2,type3,type4,type5,date,amount) &apos;, &apos;SELECT &quot;user&quot;, &quot;day&quot;, &quot;retention&quot;, &quot; &quot;, &quot;day&apos;, @dayN, &apos;&quot;, &quot;&apos;, adddate(yesterday, @`_dayOffset`), &apos;&quot;, count(DISTINCT(u.uid))&apos;, &apos;FROM users u, tmp_uuid a &apos;, &apos;WHERE u.uid = a.uuid AND &apos;, &apos;u.reg_time BETWEEN &quot;&apos;, adddate(yesterday, @`_dayOffset`), &apos; 00:00:00&quot; AND &quot;&apos;, adddate(yesterday, @`_dayOffset`), &apos; 23:59:59&quot;&apos; ); CALL SP_LogCallDebug(@_execStr); CALL SP_Exec(@_execStr, errStr); SET @days = RIGHT(@days, LENGTH(@days) - LENGTH(@dayN) - 1); END WHILE; END; END IF ; CALL SP_LogCallDebug(&apos;end.&apos;); END;]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>存储过程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSL证书生成命令]]></title>
    <url>%2FSSL%E8%AF%81%E4%B9%A6%E7%94%9F%E6%88%90%E5%91%BD%E4%BB%A4.html</url>
    <content type="text"><![CDATA[SSL证书的生成 1234567891011# 生成一个RSA密钥$ openssl genrsa -des3 -out 33iq.key 1024# 拷贝一个不需要输入密码的密钥文件$ openssl rsa -in 33iq.key -out 33iq_nopass.key# 生成一个证书请求$ openssl req -new -key 33iq.key -out 33iq.csr# 自己签发证书$ openssl x509 -req -days 365 -in 33iq.csr -signkey 33iq.key -out 33iq.crt]]></content>
      <categories>
        <category>commond</category>
      </categories>
      <tags>
        <tag>SSL</tag>
        <tag>commond</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django HTTPS配置]]></title>
    <url>%2FDjango-HTTPS%E9%85%8D%E7%BD%AE.html</url>
    <content type="text"><![CDATA[Django启动HTTPS服务的配置 在settings.py 中 添加以下配置1234SECURE_PROXY_SSL_HEADER = (&apos;HTTP_X_FORWARDED_PROTO&apos;, &apos;https&apos;)SECURE_SSL_REDIRECT = TrueSESSION_COOKIE_SECURE = TrueCSRF_COOKIE_SECURE = True - Django Django启动HTTPS服务的配置 在settings.py 中 添加以下配置1234SECURE_PROXY_SSL_HEADER = (&apos;HTTP_X_FORWARDED_PROTO&apos;, &apos;https&apos;)SECURE_SSL_REDIRECT = TrueSESSION_COOKIE_SECURE = TrueCSRF_COOKIE_SECURE = True]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Django</tag>
        <tag>HTTPS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx-HTTP-配置]]></title>
    <url>%2FNginx-HTTP-%E9%85%8D%E7%BD%AE.html</url>
    <content type="text"><![CDATA[HTTP Nginx配置的记录,和一些解析注释 1234567891011121314151617181920212223user LuGH LuGH; # 指定nginx worker进程运行用户以及用户组worker_processes 2; # 指定了nginx要开启的进程数error_log /home/LuGH/logs/nginx_log/error.log crit; # 用来定义全局错误日志文件pid /usr/local/nginx/logs/nginx.pid; # 用来指定进程id的存储文件位置events &#123; # 用来指定nginx的工作模式及连接数上限 worker_connections 1024; # 定义nginx每个进程的最大连接数&#125;http &#123; include mime.types; # 对配置文件所包含的文件设定 default_type application/octet-stream; # 为标准MIME映射未指定任何内容的文件指定默认的mime类型 sendfile on; # 用于开启高效文件传输模式 keepalive_timeout 65; # 指定了客户端与服务器长连接的超时时间 server &#123; listen 80; # 监听端口 server_name localhost; # 服务器名称 location / &#123; proxy_pass http://localhost:9000; # 忽略代理 proxy_redirect default; # 默认重定向 &#125; &#125;&#125;]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx HTTPS 的简单配置]]></title>
    <url>%2FNginx-HTTPS-%E9%85%8D%E7%BD%AE.html</url>
    <content type="text"><![CDATA[Nginx 配置的记录，和一些解析注释。 12345678910111213141516171819202122232425262728293031323334353637user LuGH LuGH; # 主模块指令，指定nginx worker进程运行用户以及用户组worker_processes 2; # 指定了nginx要开启的进程数error_log /home/LuGH/logs/nginx_log/error.log crit; # 用来定义全局错误日志文件pid /usr/local/nginx/logs/nginx.pid; # 用来指定进程id的存储文件位置events &#123; # 用来指定nginx的工作模式及连接数上限 worker_connections 1024; # 定义nginx每个进程的最大连接数&#125;http &#123; include mime.types; # 对配置文件所包含的文件设定 default_type application/octet-stream; # 为标准MIME映射未指定任何内容的文件指定默认的MIME类型。 sendfile on; # 用于开启高效文件传输模式 keepalive_timeout 65; # 指定了客户端与服务器长连接的超时时间 upstream sserver &#123; # 提供一个简单方法来实现在轮询和客户端IP之间的后端服务器负荷平衡 server 127.0.0.1:9000; # 后端服务器ip &#125; server &#123; listen 443; # 监听端口 server_name local.com; # 服务器名称 ssl on; # 开启ssl ssl_certificate /home/LuGH/key/server.crt; # ssl证书 ssl_certificate_key /home/LuGH/key/server.key; # ssl证书密匙 ssl_session_timeout 5m; # 分配客户端可以重复使用存储在缓存中的会话参数的时间。 ssl_protocols SSLv2 SSLv3 TLSv1; # 指令启用指定的协议 ssl_ciphers ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2+EXP; # 指令描述允许的密码。密码以OpenSSL支持的格式分配 ssl_prefer_server_ciphers on; # 需要协议SSLv3和TLSv1服务器密码优于客户端的密码 location / &#123; proxy_set_header X-Forwarded-Proto https; # 重新定义或添加字段传递给代理服务器的请求头 只允许https访问 proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # 识别通过HTTP代理或负载均衡方式连接到Web服务器的客户端最原始的IP地址的HTTP请求头字段是不是https proxy_set_header Host $http_host; # 设置Host proxy_redirect off; # 关闭重定向 proxy_pass http://sserver; # 忽略代理 &#125; &#125;&#125;]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
</search>
